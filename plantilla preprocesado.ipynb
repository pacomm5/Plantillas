{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pacomm5/Plantillas/blob/main/plantilla%20preprocesado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdUFcDsdzRyw"
      },
      "source": [
        "# Clonamos el repositorio para obtener los dataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHReFf3_y9ms",
        "outputId": "0305c40d-db2e-4509-cf00-1c0e528155f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'machinelearning-az'...\n",
            "remote: Enumerating objects: 10541, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 10541 (delta 25), reused 0 (delta 0), pack-reused 10505\u001b[K\n",
            "Receiving objects: 100% (10541/10541), 311.58 MiB | 22.41 MiB/s, done.\n",
            "Resolving deltas: 100% (245/245), done.\n",
            "Checking out files: 100% (10250/10250), done.\n"
          ]
        }
      ],
      "source": [
        "#!git clone https://github.com/joanby/machinelearning-az.git\n",
        "! git clone https://github.com/pacomm5/machinelearning-az # de esta manera lo que hacemos es acceder a todos los datasets mios de github. en este caso de marchine learning de la a a la z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNKZXgtKzU2x"
      },
      "source": [
        "# Damos acceso a nuestro Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gu7KWnzzUQ0",
        "outputId": "fce0b3d1-3519-4450-b03b-15754f8378dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gUxIkHWzfHV"
      },
      "source": [
        "# Test it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIQt3jBMzYRE",
        "outputId": "4cdeb636-3a5e-4bd3-a786-d974b01a4d47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'additional materials'\t LICENSE\t\t    README.md\n",
            " datasets\t\t machinelearning-az.Rproj\n"
          ]
        }
      ],
      "source": [
        "!ls '/content/machinelearning-az' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHsK36uN0XB-"
      },
      "source": [
        "# Google colab tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kTzwfUPWzrm4"
      },
      "outputs": [],
      "source": [
        "from google.colab import files # Para manejar los archivos y, por ejemplo, exportar a su navegador\n",
        "import glob # Para manejar los archivos y, por ejemplo, exportar a su navegador\n",
        "from google.colab import drive # Montar tu Google drive\n",
        "import sklearn\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yFpBwmNz70v"
      },
      "source": [
        "# Plantilla de Pre Procesado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8OxSXXSz-OP"
      },
      "source": [
        "## Cómo importar las librerías\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edZX51YLzs59"
      },
      "outputs": [],
      "source": [
        "import numpy as np # este para matemáticas. \n",
        "import matplotlib.pyplot as plt # este para gráficos\n",
        "import pandas as pd # perfecta carga, manipular.... datos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XfXlqtF0B58"
      },
      "source": [
        "## Importar el data set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        },
        "id": "-nnozsHsz_-N",
        "outputId": "9aaa1d3f-326c-489e-8b27-72f728f94131"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' escribiendo código\\nX = dataset.iloc[:,:-1].values\\ny = dataset.iloc[:, 3]'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dataset = pd.read_csv('/content/machinelearning-az/datasets/Part 1 - Data Preprocessing/Section 2 -------------------- Part 1 - Data Preprocessing --------------------/Data.csv')\n",
        "\n",
        "X = dataset.iloc[:, :-1].values # con esto quitamos la variable dependiente que es purchased. poenmos .values para que nos saque los valores. \n",
        "y = dataset.iloc[:, 3].values # aqui dejamos la variable  independientes. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "después de realizar esto tendremos las variables independientes en X y la variable dependiente en y. ambos son arrays"
      ],
      "metadata": {
        "id": "5BMzE_JuOMTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PROBLEMAS DE FORMATO AL IMPORTAR"
      ],
      "metadata": {
        "id": "PJ7Wl5oYYoy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/TRABAJO MASTER/df_est_total.csv\", sep=\"|\", encoding=\"ISO-8859-1\")"
      ],
      "metadata": {
        "id": "UM6_w6OjYtKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VER LOS NOMBRES DE LAS COLUMNAS QUE TIENE"
      ],
      "metadata": {
        "id": "mtrDW3usZMW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "SWh1GbqPZQxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ver el tipo de formato de las variables etc..."
      ],
      "metadata": {
        "id": "OHM_OEficMtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.types con esto vemos el tipo de las variables. "
      ],
      "metadata": {
        "id": "KMDhkHyccR6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.describe() # con esto vemos contar, media minimoo max quartiles. "
      ],
      "metadata": {
        "id": "QBAu5PXJcUvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.isnull().sum() #para ver los nan"
      ],
      "metadata": {
        "id": "faBhGrs0crd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape # con esto vemos la forma de dataframe, también lo podemos hacer con un array. "
      ],
      "metadata": {
        "id": "efTWtFNdf_fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CONVERTIR EL TIPO DE VARIABLES. "
      ],
      "metadata": {
        "id": "h8UczwOIhJ0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['id_cl']=df['id_cl'].apply(str)\n",
        "df[\"anno\"] = df[\"anno\"].apply(str)\n",
        "df[\"mes\"] = df[\"mes\"].apply(str)\n",
        "df[\"cod_sector\"] = df[\"cod_sector\"].apply(str)\n",
        "df[\"provincia\"] = df[\"provincia\"].apply(str)"
      ],
      "metadata": {
        "id": "5ejjokQ1hOGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# con esto creamos la columna de fecha desde varias columnas. \n",
        "\n",
        "\n",
        "df[\"Fecha\"] = df[\"anno\"] + \"/\" + df[\"mes\"] \n",
        "#data[\"Fecha\"] = data[\"anno\"] + \"/\" + data[\"mes\"] + \"/\" + \"01\"\n",
        "df.Fecha = pd.to_datetime(df.Fecha, dayfirst = True)"
      ],
      "metadata": {
        "id": "rgQGmrOtheoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RENOMBRAR VARIABLES. "
      ],
      "metadata": {
        "id": "g-zIXxzVjwd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_gr_cl = df_gr_cl.rename(columns={'importe2':'imp2_tot_cl'}).reset_index()"
      ],
      "metadata": {
        "id": "3wWbcPPmjzOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RESET INDEX"
      ],
      "metadata": {
        "id": "7Bd4Eu6Q6i5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3.reset_index(inplace=True, drop=True)\n",
        "df3.head()"
      ],
      "metadata": {
        "id": "s50_RR0C6qVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FILTRAR DATASET"
      ],
      "metadata": {
        "id": "XHkLkxcQQI-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.iloc[:, 0:3].head() # esto no vale para nada es para ver como filtrar un data set. \n",
        "# NO HEMOS ASIGNADO VARIABLE POR LO TANTO NO CAMBIA NADA SOLO SE VISUALIZA"
      ],
      "metadata": {
        "id": "qjMdfhfXQM39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "también lo podemos hacer así. "
      ],
      "metadata": {
        "id": "7UWrS2fwZ6rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df1[[\"id_cl\", \"Fecha\"]] # vamos introduciendo todas las columnas que queramos. \n",
        "# se colocarán en el orden que las pongamos. "
      ],
      "metadata": {
        "id": "h0MCGg5CZ9WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FILTRAR POR FECHA"
      ],
      "metadata": {
        "id": "_bl4NVQWepcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_date = pd.datetime(2018,12,1)\n",
        "df_fecha_cl = df_fecha_cl0.loc[df_fecha_cl0.index <= split_date].copy()\n",
        "df_fecha_cl.head(30)\n",
        "# con esto filtramos por fecha menor o igual al split_date"
      ],
      "metadata": {
        "id": "0CLSDfmyesY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### filtrar por fila"
      ],
      "metadata": {
        "id": "6GU2dzH1sz4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"nombre de la columna\"]==\"nombre de lo que queremos filtrar \"\n",
        "df[\"nombre de la columna\"]==\"300\" # filtro por un valor. "
      ],
      "metadata": {
        "id": "jQyLmHrAs2nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mask = df2[(df2.PIB >0) & (df2.cotiz_empleadores>0)] # aqui estamos filtrando por dos condiciones.\n",
        "df_mask = df2[(df2.PIB >0)]# aqui por una condición"
      ],
      "metadata": {
        "id": "6b3CkM813r6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AGRUPAR POR UNA VARIABLE. "
      ],
      "metadata": {
        "id": "kZcRV59miU_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_gr_cl=pd.DataFrame(df_fecha.groupby('id_cl')['importe2'].sum())"
      ],
      "metadata": {
        "id": "IZZAyC28iYhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr_activ=df_fecha.groupby(['rama_actividad','desc_actividad']).count() # AGRUPAR Y CONTAR "
      ],
      "metadata": {
        "id": "_US3-_SLiSWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = df3.groupby([\"Fecha\", \"desc_actividad\"]).agg({\"importe2\":[\"sum\"], \"PIB\":[\"mean\"], \"cotiz_empleadores\":[\"mean\"]}).reset_index()\n",
        "df5.head()\n",
        "# agrupar por varias variables y asignandoles una función diferente. \n",
        "# ejemplo el importe2 lo sumamos, el importe hacemos la media, y la cotizacion hacemos la media. \n",
        "\n",
        "# OJO ESTO GENERA UN PROBLEMA YA QUE LAS COLUMNAS SE CONVIERTEN EN MULTIINDEX\n",
        "# PARA QUITARLO HACEMOS ESTO\n",
        "df5.columns = [\"Fecha\", \"desc_actividad\", \"importe2\", \"PIB\", \"cotiz_empleadores\"] \n",
        "# lo que hacemos es renombrar las columnas y se quita. "
      ],
      "metadata": {
        "id": "GgnCY-mZDWnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MOVER UNA COLUMNA DE POSICION"
      ],
      "metadata": {
        "id": "BDMB0byCRWbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# si por ejemplo tenemos un df = con las columnas a,b,c,d,e,f\n",
        "# y queremos monver la columna b al último lugar lo hacemos así. \n",
        "# df= df[[\"a\", \"c\", \"d\", \"e\", \"f\", \"a\"]]\n",
        "# de esta manera la colocaremos al final. muy util para separa variables independientes de las independientes. \n",
        "# servirça para filtrar y tambien para recolocar las filas. "
      ],
      "metadata": {
        "id": "sRYtMNVSRavR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# otra manera sería así. \n",
        "# df.reindex(columns=[\"a\", \"c\", \"d\", \"e\", \"f\", \"a\"])"
      ],
      "metadata": {
        "id": "YoYrnIOATDdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INTRODUCIR UNA NUEVA COLUMNA"
      ],
      "metadata": {
        "id": "4qHN0FjOSVak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# si queremos meter una nueva columna se hace así. \n",
        "# df.insert(0, \"nombre de la columna\", df.mean(1)) en este caso hemos insertado una nueva columna \n",
        "# en la posición 0, y el valor que hemos metido es la media de toda la fila."
      ],
      "metadata": {
        "id": "fGk8gFIWSZkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UNIMOS DOS DATASET"
      ],
      "metadata": {
        "id": "Ro5_OT7rT625"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# si queremos unir dos dataset se hace así. \n",
        "# dataset4 = pd.concat([dataset2,dataset3], axis=1, join=\"inner\")"
      ],
      "metadata": {
        "id": "zS3FhjiWUDIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UNIR DOS DATASET CON CLAVE PRIMARIA"
      ],
      "metadata": {
        "id": "naMZ1YgKeKsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_fecha_tot=pd.merge(df_fecha,df_cl_tot,left_on=['id_cl','Fecha'], right_on=['id_cl','Fecha'],how='left')"
      ],
      "metadata": {
        "id": "OdEFDVO4eQc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATOS FALTANTES VALORES NAN"
      ],
      "metadata": {
        "id": "d8NWpQuiRvMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "con los datos faltantes podemos hacer muchas cosas. eliminar la columna, la fila, rellenar con un valor, rellenar con la media, con el valor anterior, posterior etc..."
      ],
      "metadata": {
        "id": "K9iqKAakR_JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum().sort_value(ascending = False) # con esto sacamos el resumen y ordenador de mayor a menor\n",
        "# si queremos ver el porcentaje lo hacemos de la siguiente manera. \n",
        "percent = (df.isnull().sum() / df.isnull().count().sort_values(ascending = False))"
      ],
      "metadata": {
        "id": "4Z52KePKgRkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna(0) # con esto rellenamos los valores faltantes a 0"
      ],
      "metadata": {
        "id": "iKoQpSBuhUxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core import missing\n",
        "# VAMOS A REMPLAZAR POR LA MEDIA. \n",
        "# recordatorio axis = 0 es media de columna si fuera 1 sería por linea. \n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy = \"mean\", verbose=0) # asi lo que hacemos es convertir los valores nan por la media de la columna. \n",
        "imputer = imputer.fit(X[:,1:3]) # el objeto que queremos arreglar es la X, le decimos que todas las filas, y acotamos las columnas a las que se lo queremos hacer. recordar ponemos 3 porque coge siempre la anterior. \n",
        "# en python la primera columna es 0 y cuando acotamos la última que cogemos siempre ponemos un numero más. \n",
        "X[:, 1:3] = imputer.transform(X[:,1:3]) # asi es como definitivamente lo hacemos. \n",
        " \n",
        "\"\"\"\n",
        "Escribimos código\n",
        "imputer = SimpleImputer(missing_values= np.nan, strategy= \"mean\", verbose=0)\n",
        "imputer = imputer.fit(X[:,1:3])\n",
        "x[:,1:3] = imputer.transform[X[:,1:3]] \"\"\"\n",
        "X # veremos debajo que ha quedado sustituido."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TGfIEGiRyYa",
        "outputId": "6af4d878-46a4-4036-9352-15f9e032b5ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['France', 44.0, 72000.0],\n",
              "       ['Spain', 27.0, 48000.0],\n",
              "       ['Germany', 30.0, 54000.0],\n",
              "       ['Spain', 38.0, 61000.0],\n",
              "       ['Germany', 40.0, 63777.77777777778],\n",
              "       ['France', 35.0, 58000.0],\n",
              "       ['Spain', 38.77777777777778, 52000.0],\n",
              "       ['France', 48.0, 79000.0],\n",
              "       ['Germany', 50.0, 83000.0],\n",
              "       ['France', 37.0, 67000.0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATOS CATEGORICOS TRADUCIR A NUMEROS. "
      ],
      "metadata": {
        "id": "T6UQlhK6dcSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lo que vamos a hacer estraducir los datos categoriocs a números. ejemplo españa 1, alemania 2 ..."
      ],
      "metadata": {
        "id": "mvAKnqzOd9Dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer"
      ],
      "metadata": {
        "id": "j2EqI_SYdhCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "hay dos maneras de hacerlo. la primera lo pone como numeros en una columna. pero eso puede dar luegar a que los entienda como ordinales. la otra manera es ponerlos en columnas."
      ],
      "metadata": {
        "id": "gRArkGNWOuCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OJOO NO HAY QUE CODIFICARLO ASÍ PORQUE TE LO PONE EN UNA UNICA COLUMNA Y LO PUEDE CONSIDERAR ORDINAL\n",
        "#labelencoder_X = LabelEncoder() # este es el constructor \n",
        "#X[:, 0] = labelencoder_X.fit_transform(X[:, 0]) # sabemos que 0 es la columna de país. \n",
        "#X[:,0] # como podemos ver la primera que era Francia la ha codificado como 0, la seguna españa 2, la tercera alemania 1...."
      ],
      "metadata": {
        "id": "aFaPOksJdnNh",
        "outputId": "a91d4b66-bc23-4f99-85a3-06be67701bc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 1, 2, 1, 0, 2, 0, 1, 0], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X # aqui vemos como lo ha cambiado. el problema que al codificarlo así, va a entender que 0 es menor que 1. es decir la va a considerar como ordinal.....\n",
        "# ahora debajo vamos a ver las variables dummy. "
      ],
      "metadata": {
        "id": "IuXlTsYlfVKG",
        "outputId": "520f15ff-b9d0-43b5-dddf-e7b8c85ddafc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 44.0, 72000.0],\n",
              "       [2, 27.0, 48000.0],\n",
              "       [1, 30.0, 54000.0],\n",
              "       [2, 38.0, 61000.0],\n",
              "       [1, 40.0, 63777.77777777778],\n",
              "       [0, 35.0, 58000.0],\n",
              "       [2, 38.77777777777778, 52000.0],\n",
              "       [0, 48.0, 79000.0],\n",
              "       [1, 50.0, 83000.0],\n",
              "       [0, 37.0, 67000.0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "esta es la segunda manera con la que lo que hace es ponerlo en columnas. "
      ],
      "metadata": {
        "id": "RTqmkP7ePC8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ct = ColumnTransformer(\n",
        "    [('one_hot_encoder', OneHotEncoder(categories='auto'), [0])],    # The column numbers to be transformed (here is [0] but can be [0, 1, 3])\n",
        "    remainder='passthrough'                         # Leave the rest of the columns untouched\n",
        ")\n"
      ],
      "metadata": {
        "id": "WVDrNshWdsPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = ct.fit_transform(X)\n",
        "X # vemos que aquí ya lo ha transformado, p"
      ],
      "metadata": {
        "id": "NB_915QqhA4d",
        "outputId": "6d984398-d7fa-4590-810a-8c1a6751a65b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0, 0.0, 0.0, 44.0, 72000.0],\n",
              "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
              "       [0.0, 1.0, 0.0, 30.0, 54000.0],\n",
              "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
              "       [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
              "       [1.0, 0.0, 0.0, 35.0, 58000.0],\n",
              "       [0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
              "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
              "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
              "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "aqui lo hacemo de una vez este segundo metodo"
      ],
      "metadata": {
        "id": "4Ly6zr9NVuSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "labelencoder_X = LabelEncoder()\n",
        "X[:, 3] = labelencoder_X.fit_transform(X[:, 3])\n",
        "onehotencoder = make_column_transformer((OneHotEncoder(), [3]), remainder = \"passthrough\")\n",
        "X = onehotencoder.fit_transform(X)\"\"\""
      ],
      "metadata": {
        "id": "kgHEs9FdVy15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###EVITAR LA TRAS DE LAS VARIABLES FICTICIAS. "
      ],
      "metadata": {
        "id": "C287Vz2jQfBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X[:, 1:] # con esto lo que hacemos es eliminar una ya que cuando dos den 0 será la tercera. "
      ],
      "metadata": {
        "id": "tfaSaX01Qn5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8PABYut0i7y"
      },
      "source": [
        "## Dividir el data set en conjunto de entrenamiento y conjunto de testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPVZUP870DoR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lajo7ye0lEs"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0) # random_state es la semilla. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRANSFORMAR UN ARRAY EN DATAFRAME"
      ],
      "metadata": {
        "id": "562sg02LWccC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.DataFrame({'California': X[:, 0], 'Florida': X[:, 1],'New York': X[:, 2]})\n",
        "#result = pd.DataFrame({'Column1': X[:, 0], 'Column2': X[:, 1],'Column3': X[:, 2]})\n",
        "# esto entiendo es para convertir el array en un dataframe. "
      ],
      "metadata": {
        "id": "UhpexPAXWgnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRMD7_oq3J_f"
      },
      "source": [
        "## Escalado de variables"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### StandarScaler"
      ],
      "metadata": {
        "id": "UnL4e1T7PTbx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ-MnRSO0md2"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler # esta tenderá a crear una campana de gauss. aglutina valores en torno a la media. \n",
        "# la normalización, transforma en 0 y 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt9uD3hE0nxd"
      },
      "outputs": [],
      "source": [
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test) # aqui le decimos que escale igual que en X_train. \n",
        "# la pregunta sería ¿tenemos que escalar las variables dummy?.  AQUI SI LO HACEMOS. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ymwl8fsHESF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train # como vemos al haberlo transformados el 0 1 de los paises se ha convertido en numeros diferentes. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBCCLAxdBHve",
        "outputId": "5ed1fe2a-b2fc-4331-ad6d-49d8b47ebc55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.        ,  2.64575131, -0.77459667,  0.26306757,  0.12381479],\n",
              "       [ 1.        , -0.37796447, -0.77459667, -0.25350148,  0.46175632],\n",
              "       [-1.        , -0.37796447,  1.29099445, -1.97539832, -1.53093341],\n",
              "       [-1.        , -0.37796447,  1.29099445,  0.05261351, -1.11141978],\n",
              "       [ 1.        , -0.37796447, -0.77459667,  1.64058505,  1.7202972 ],\n",
              "       [-1.        , -0.37796447,  1.29099445, -0.0813118 , -0.16751412],\n",
              "       [ 1.        , -0.37796447, -0.77459667,  0.95182631,  0.98614835],\n",
              "       [ 1.        , -0.37796447, -0.77459667, -0.59788085, -0.48214934]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VsVa0hfBJjb",
        "outputId": "c4751a1e-37ad-4238-a74e-921d5a6bb0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.        ,  2.64575131, -0.77459667, -1.45882927, -0.90166297],\n",
              "       [-1.        ,  2.64575131, -0.77459667,  1.98496442,  2.13981082]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ujM43nSnEWHT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "data_preprocessing_template.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}